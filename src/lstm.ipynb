{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:22.511792Z",
     "iopub.status.busy": "2026-02-02T11:01:22.511389Z",
     "iopub.status.idle": "2026-02-02T11:01:25.908043Z",
     "shell.execute_reply": "2026-02-02T11:01:25.906944Z",
     "shell.execute_reply.started": "2026-02-02T11:01:22.511764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:25.910104Z",
     "iopub.status.busy": "2026-02-02T11:01:25.909805Z",
     "iopub.status.idle": "2026-02-02T11:01:25.919128Z",
     "shell.execute_reply": "2026-02-02T11:01:25.918144Z",
     "shell.execute_reply.started": "2026-02-02T11:01:25.910073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: Tesla T4\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Literal\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "\n",
    "\n",
    "#BASE_RESULTS_DIR = \"lstm_results\"\n",
    "BASE_RESULTS_DIR = \"/kaggle/working/lstm_results\"\n",
    "\n",
    "WITHIN_DIR = os.path.join(BASE_RESULTS_DIR, \"within_subject\")\n",
    "CROSS_DIR = os.path.join(BASE_RESULTS_DIR, \"cross_subject\")\n",
    "\n",
    "os.makedirs(WITHIN_DIR, exist_ok=True)\n",
    "os.makedirs(CROSS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#DATA_PATH = \"data/data.npz\"\n",
    "DATA_PATH = \"/kaggle/input/data-npz/data.npz\"\n",
    "CHANNELS = [\"EEG.AF3\", \"EEG.T7\", \"EEG.Pz\", \"EEG.T8\", \"EEG.AF4\"]\n",
    "CHANNEL_TO_IDX = { c: idx for idx, c in enumerate(CHANNELS) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:25.920610Z",
     "iopub.status.busy": "2026-02-02T11:01:25.920334Z",
     "iopub.status.idle": "2026-02-02T11:01:25.940156Z",
     "shell.execute_reply": "2026-02-02T11:01:25.939212Z",
     "shell.execute_reply.started": "2026-02-02T11:01:25.920586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def eval_on_loader_bce(model: nn.Module, loader: DataLoader, device: str):\n",
    "    model.eval()\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    losses, correct, total = [], 0, 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= 0.5).float()\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.numel()\n",
    "\n",
    "    return float(np.mean(losses)), (correct / total if total else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:25.942900Z",
     "iopub.status.busy": "2026-02-02T11:01:25.942538Z",
     "iopub.status.idle": "2026-02-02T11:01:25.959618Z",
     "shell.execute_reply": "2026-02-02T11:01:25.958974Z",
     "shell.execute_reply.started": "2026-02-02T11:01:25.942874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_path, normalize: bool = True):\n",
    "    data = np.load(data_path)\n",
    "    X, y = data[\"X_raw\"], data[\"y\"]\n",
    "\n",
    "    if X.ndim != 5 or y.ndim != 3:\n",
    "        raise ValueError(\"X must be 5D and y 3D\")\n",
    "\n",
    "    n_sub, n_sess, n_chan, n_trials, n_samples = X.shape\n",
    "\n",
    "    print(f\"X original: {X.shape}\")\n",
    "    print(f\"y original: {y.shape}\")\n",
    "\n",
    "    if normalize:\n",
    "        X_mean = X.mean(axis=-1, keepdims=True)\n",
    "        X_std = X.std(axis=-1, keepdims=True) + 1e-6\n",
    "        X = (X - X_mean) / X_std\n",
    "        \n",
    "    X_transposed = X.transpose(0, 1, 3, 2, 4)  # (sub, sess, trial, chan, time)\n",
    "    X_new = X_transposed.reshape(n_sub, n_sess * n_trials, n_chan, n_samples)\n",
    "    y_new = y.reshape(n_sub, n_sess * n_trials)\n",
    "\n",
    "    if X_new.shape[1] != y_new.shape[1]:\n",
    "        raise RuntimeError(f\"Mismatch: X_new {X_new.shape}, y_new {y_new.shape}\")\n",
    "\n",
    "    unique_labels = np.unique(y_new)\n",
    "    if not set(unique_labels).issubset({0, 1}):\n",
    "        raise RuntimeError(f\"Non binary labels found: {unique_labels}\")\n",
    "\n",
    "    print(f\"X final: {X_new.shape}\")\n",
    "    print(f\"y final: {y_new.shape}\")\n",
    "\n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:25.961286Z",
     "iopub.status.busy": "2026-02-02T11:01:25.960858Z",
     "iopub.status.idle": "2026-02-02T11:01:25.986337Z",
     "shell.execute_reply": "2026-02-02T11:01:25.985586Z",
     "shell.execute_reply.started": "2026-02-02T11:01:25.961248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_results_csv(results_dict, save_dir, prefix, model_args, epochs):\n",
    "    rows = []\n",
    "    for combo, stats in results_dict.items():\n",
    "        rows.append({\n",
    "            \"channels\": combo,\n",
    "            \"mean_accuracy\": stats[\"mean\"],\n",
    "            \"std_accuracy\": stats[\"std\"],\n",
    "            \"lstm_hidden\": model_args[\"lstm_hidden\"],\n",
    "            \"lstm_layers\": model_args[\"lstm_layers\"],\n",
    "            \"dropout\": model_args[\"dropout\"],\n",
    "            \"epochs\": epochs\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    fname = (\n",
    "        f\"{prefix}_lstm_h{model_args['lstm_hidden']}\"\n",
    "        f\"_l{model_args['lstm_layers']}\"\n",
    "        f\"_do{model_args['dropout']}\"\n",
    "        f\"_ep{epochs}.csv\"\n",
    "    )\n",
    "\n",
    "    save_path = os.path.join(save_dir, fname)\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    print(f\"Saved results to: {save_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_results_json(results_data, save_dir, prefix, model_args):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    fname = (\n",
    "        f\"{prefix}_lstm_h{model_args['lstm_hidden']}\"\n",
    "        f\"_l{model_args['lstm_layers']}\"\n",
    "        f\"_do{model_args['dropout']}.json\"\n",
    "    )\n",
    "    save_path = os.path.join(save_dir, fname)\n",
    "    \n",
    "    \n",
    "    def convert_numpy(obj):\n",
    "        if isinstance(obj, np.integer): return int(obj)\n",
    "        if isinstance(obj, np.floating): return float(obj)\n",
    "        if isinstance(obj, np.ndarray): return obj.tolist()\n",
    "        return obj\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(results_data, f, indent=2, default=convert_numpy)\n",
    "\n",
    "    print(f\"Saved JSON results to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:25.987823Z",
     "iopub.status.busy": "2026-02-02T11:01:25.987462Z",
     "iopub.status.idle": "2026-02-02T11:01:26.173839Z",
     "shell.execute_reply": "2026-02-02T11:01:26.173102Z",
     "shell.execute_reply.started": "2026-02-02T11:01:25.987787Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X original: (27, 2, 5, 25, 384)\n",
      "y original: (27, 2, 25)\n",
      "X final: (27, 50, 5, 384)\n",
      "y final: (27, 50)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(DATA_PATH, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:26.175071Z",
     "iopub.status.busy": "2026-02-02T11:01:26.174755Z",
     "iopub.status.idle": "2026-02-02T11:01:26.183075Z",
     "shell.execute_reply": "2026-02-02T11:01:26.182271Z",
     "shell.execute_reply.started": "2026-02-02T11:01:26.175036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EEGLieFeatureExtractor(nn.Module):\n",
    "    def __init__(self, n_channels=5, seq_len=384, tcn_channels=64, kernel_size=5,\n",
    "                 lstm_hidden=128, lstm_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TCN: stack of 1D convs\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.Conv1d(n_channels, tcn_channels, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm([tcn_channels, seq_len]),\n",
    "            nn.Conv1d(tcn_channels, tcn_channels, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm([tcn_channels, seq_len]),\n",
    "            nn.MaxPool1d(2)  # Reduce sequence length\n",
    "        )\n",
    "        \n",
    "        # BiLSTM for long-term temporal dynamics\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=tcn_channels,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Head (feature vector output)\n",
    "        self.classifier = nn.Linear(2 * lstm_hidden, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TCN\n",
    "        x = self.tcn(x)                     # (batch, tcn_channels, seq_len//2)\n",
    "        x = x.transpose(1, 2)               # (batch, seq_len//2, tcn_channels) for LSTM\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x)          # (batch, seq_len//2, 2*lstm_hidden)\n",
    "        \n",
    "        return self.classifier(lstm_out[:, -1, :])  # (batch, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross subject LOSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:26.184660Z",
     "iopub.status.busy": "2026-02-02T11:01:26.184329Z",
     "iopub.status.idle": "2026-02-02T11:01:26.208090Z",
     "shell.execute_reply": "2026-02-02T11:01:26.207287Z",
     "shell.execute_reply.started": "2026-02-02T11:01:26.184610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def cross_subject_loso(X, y, channels, model_args, epochs):\n",
    "    n_subjects = X.shape[0]\n",
    "    channel_indices = list(range(len(channels)))\n",
    "    results = {}\n",
    "    \n",
    "    # Generate all non-empty combinations of channels\n",
    "    all_combos = []\n",
    "    for r in range(1, len(channels) + 1):\n",
    "        all_combos.extend(list(itertools.combinations(channel_indices, r)))\n",
    "    \n",
    "    for combo in all_combos:\n",
    "        combo_names = [channels[i] for i in combo]\n",
    "        combo_key = \", \".join(combo_names)\n",
    "        print(f\"\\n===== Analyzing Combo: {combo_key} =====\")\n",
    "        subject_accuracies = []\n",
    "        \n",
    "        for test_sub in range(n_subjects):\n",
    "            train_subs = [i for i in range(n_subjects) if i != test_sub]\n",
    "            \n",
    "            # Prepare train and test tensors\n",
    "            X_train = torch.FloatTensor(X[train_subs][:, :, combo, :]).reshape(-1, len(combo), 384).to(device)\n",
    "            y_train = torch.FloatTensor(y[train_subs]).reshape(-1, 1).to(device)\n",
    "            \n",
    "            X_test = torch.FloatTensor(X[test_sub:test_sub+1][:, :, combo, :]).reshape(-1, len(combo), 384).to(device)\n",
    "            y_test = y[test_sub].flatten()\n",
    "            \n",
    "            # Instantiate model\n",
    "            model_args['n_channels'] = len(combo)\n",
    "            model = EEGLieFeatureExtractor(**model_args).to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr)\n",
    "            criterion = nn.BCEWithLogitsLoss()  # use logits later if needed\n",
    "            \n",
    "            # Training loop\n",
    "            \n",
    "            train_ds = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "            X_test_t = X_test.to(device)\n",
    "            y_test_t = torch.FloatTensor(y_test).view(-1, 1).to(device)\n",
    "            test_ds = TensorDataset(X_test_t, y_test_t)\n",
    "            test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "            best_val = float(\"inf\")\n",
    "            best_state = None\n",
    "\n",
    "            # Training + validation (LOSO: test subject = validation)\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                for xb, yb in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model(xb)\n",
    "                    loss = criterion(logits, yb)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                val_loss, val_acc = eval_on_loader_bce(\n",
    "                    model, test_loader, device\n",
    "                )\n",
    "\n",
    "                if val_loss < best_val:\n",
    "                    best_val = val_loss\n",
    "                    best_state = {\n",
    "                        k: v.detach().cpu().clone()\n",
    "                        for k, v in model.state_dict().items()\n",
    "                    }\n",
    "\n",
    "            # Load best model\n",
    "            model.load_state_dict(best_state)\n",
    "\n",
    "            # Final evaluation (accuracy of best model)\n",
    "            _, best_acc = eval_on_loader_bce(\n",
    "                model, test_loader, device\n",
    "            )\n",
    "\n",
    "            subject_accuracies.append(best_acc)\n",
    "\n",
    "        \n",
    "        # Compute mean and std accuracy\n",
    "        mean_acc = np.mean(subject_accuracies)\n",
    "        std_acc = np.std(subject_accuracies)\n",
    "        results[combo_key] = {'mean': mean_acc, 'std': std_acc}\n",
    "        print(f\"Combo Result -> Mean: {mean_acc:.4f} | STD: {std_acc:.4f}\")\n",
    "    \n",
    "    return results\n",
    "'''\n",
    "\n",
    "def cross_subject_loso(X, y, channels, model_args, epochs, val_split=0.2):\n",
    "    n_subjects = X.shape[0]\n",
    "    channel_indices = list(range(len(channels)))\n",
    "    results = {} \n",
    "    \n",
    "    \n",
    "    all_combos = []\n",
    "    for r in range(1, len(channels) + 1):\n",
    "        all_combos.extend(list(itertools.combinations(channel_indices, r)))\n",
    "    \n",
    "    for combo in all_combos:\n",
    "        combo_names = [channels[i] for i in combo]\n",
    "        combo_key = \"+\".join(combo_names)\n",
    "        print(f\"\\n===== CROSS-SUBJECT | Combo: {combo_key} =====\")\n",
    "        \n",
    "        subject_accuracies = []\n",
    "        \n",
    "        \n",
    "        for test_sub in range(n_subjects):\n",
    "            train_subs = [i for i in range(n_subjects) if i != test_sub]\n",
    "            \n",
    "            \n",
    "            X_train_full = torch.FloatTensor(X[train_subs][:, :, combo, :]).reshape(-1, len(combo), 384)\n",
    "            y_train_full = torch.FloatTensor(y[train_subs]).reshape(-1, 1)\n",
    "            \n",
    "            \n",
    "            X_test = torch.FloatTensor(X[test_sub:test_sub+1][:, :, combo, :]).reshape(-1, len(combo), 384).to(device)\n",
    "            y_test = torch.FloatTensor(y[test_sub].flatten()).view(-1, 1).to(device)\n",
    "            \n",
    "            # ---  Validation Split (ANTI-LEAKAGE) ---\n",
    "            \n",
    "            X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "                X_train_full, y_train_full, \n",
    "                test_size=val_split, \n",
    "                random_state=42,\n",
    "                stratify=y_train_full\n",
    "            )\n",
    "            \n",
    "            X_tr, X_val = X_tr.to(device), X_val.to(device)\n",
    "            y_tr, y_val = y_tr.to(device), y_val.to(device)\n",
    "\n",
    "            # --- Training Setup ---\n",
    "            train_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=64, shuffle=True)\n",
    "            val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "            test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
    "\n",
    "            model_args['n_channels'] = len(combo)\n",
    "            model = EEGLieFeatureExtractor(**model_args).to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=model_args.get('lr', 1e-3))\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            \n",
    "            best_val_loss = float(\"inf\")\n",
    "            best_state = None\n",
    "\n",
    "            # ---Training Loop ---\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                for xb, yb in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model(xb)\n",
    "                    loss = criterion(logits, yb)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Check on Validation Set (NON on Test)\n",
    "                val_loss, _ = eval_on_loader_bce(model, val_loader, device)\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "            \n",
    "            if best_state is not None:\n",
    "                model.load_state_dict(best_state)\n",
    "            \n",
    "            \n",
    "            _, test_acc = eval_on_loader_bce(model, test_loader, device)\n",
    "            subject_accuracies.append(test_acc)\n",
    "            \n",
    "            # print(f\"  Subj {test_sub+1}: {test_acc:.4f}\") \n",
    "\n",
    "        \n",
    "        mean_acc = np.mean(subject_accuracies)\n",
    "        std_acc = np.std(subject_accuracies)\n",
    "        \n",
    "        \n",
    "        results[combo_key] = {\n",
    "            'per_subject': subject_accuracies,\n",
    "            'mean': mean_acc, \n",
    "            'std': std_acc\n",
    "        }\n",
    "        print(f\"Result -> Mean: {mean_acc:.4f} | STD: {std_acc:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within subjects LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:26.209454Z",
     "iopub.status.busy": "2026-02-02T11:01:26.209171Z",
     "iopub.status.idle": "2026-02-02T11:01:26.228439Z",
     "shell.execute_reply": "2026-02-02T11:01:26.227861Z",
     "shell.execute_reply.started": "2026-02-02T11:01:26.209422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def within_subject_loocv(X, y, channels, model_args, epochs):\n",
    "    n_subjects = X.shape[0]\n",
    "    channel_indices = list(range(len(channels)))\n",
    "    results = {}\n",
    "\n",
    "    \n",
    "    all_combos = []\n",
    "    for r in range(1, len(channels) + 1):\n",
    "        all_combos.extend(list(itertools.combinations(channel_indices, r)))\n",
    "\n",
    "    for combo in all_combos:\n",
    "        combo_names = [channels[i] for i in combo]\n",
    "        combo_key = \", \".join(combo_names)\n",
    "        print(f\"\\n===== Within-Subject | Combo: {combo_key} =====\")\n",
    "\n",
    "        subject_accuracies = []\n",
    "\n",
    "        for subj in range(n_subjects):\n",
    "            X_subj = X[subj][:, combo, :]      # (trials, channels, seq)\n",
    "            y_subj = y[subj]                   # (trials,)\n",
    "\n",
    "            n_trials = X_subj.shape[0]\n",
    "\n",
    "            for test_idx in range(n_trials):\n",
    "                train_idx = [i for i in range(n_trials) if i != test_idx]\n",
    "\n",
    "                X_train = torch.FloatTensor(X_subj[train_idx]).to(device)\n",
    "                y_train = torch.FloatTensor(y_subj[train_idx]).view(-1, 1).to(device)\n",
    "\n",
    "                X_test = torch.FloatTensor(X_subj[test_idx:test_idx+1]).to(device)\n",
    "                y_test = torch.FloatTensor([y_subj[test_idx]]).view(-1, 1).to(device)\n",
    "\n",
    "                train_ds = TensorDataset(X_train, y_train)\n",
    "                train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "                test_ds = TensorDataset(X_test, y_test)\n",
    "                test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "                model_args[\"n_channels\"] = len(combo)\n",
    "                model = EEGLieFeatureExtractor(**model_args).to(device)\n",
    "                optimizer = optim.Adam(model.parameters(), lr)\n",
    "                criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "                best_val = float(\"inf\")\n",
    "                best_state = None\n",
    "\n",
    "                for epoch in range(epochs):\n",
    "                    model.train()\n",
    "                    for xb, yb in train_loader:\n",
    "                        optimizer.zero_grad()\n",
    "                        logits = model(xb)\n",
    "                        loss = criterion(logits, yb)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    val_loss, _ = eval_on_loader_bce(model, test_loader, device)\n",
    "                    if val_loss < best_val:\n",
    "                        best_val = val_loss\n",
    "                        best_state = {\n",
    "                            k: v.detach().cpu().clone()\n",
    "                            for k, v in model.state_dict().items()\n",
    "                        }\n",
    "\n",
    "                model.load_state_dict(best_state)\n",
    "                _, acc = eval_on_loader_bce(model, test_loader, device)\n",
    "                subject_accuracies.append(acc)\n",
    "\n",
    "        mean_acc = np.mean(subject_accuracies)\n",
    "        std_acc = np.std(subject_accuracies)\n",
    "        results[combo_key] = {\"mean\": mean_acc, \"std\": std_acc}\n",
    "\n",
    "        print(f\"Within-Subject Result -> Mean: {mean_acc:.4f} | STD: {std_acc:.4f}\")\n",
    "\n",
    "    return results\n",
    "'''\n",
    "def within_subject_loocv(X, y, channels, model_args, epochs, val_split=0.2):\n",
    "    n_subjects = X.shape[0]\n",
    "    channel_indices = list(range(len(channels)))\n",
    "    results = [] \n",
    "\n",
    "    all_combos = []\n",
    "    for r in range(1, len(channels) + 1):\n",
    "        all_combos.extend(list(itertools.combinations(channel_indices, r)))\n",
    "\n",
    "    for combo in all_combos:\n",
    "        combo_names = [channels[i] for i in combo]\n",
    "        combo_key = \"+\".join(combo_names)\n",
    "        print(f\"\\n===== WITHIN-SUBJECT | Combo: {combo_key} =====\")\n",
    "\n",
    "        for subj in range(n_subjects):\n",
    "            X_subj = X[subj][:, combo, :] \n",
    "            y_subj = y[subj]\n",
    "            n_trials = X_subj.shape[0]\n",
    "\n",
    "            fold_accuracies = []\n",
    "\n",
    "            \n",
    "            for test_idx in range(n_trials):\n",
    "                \n",
    "                train_indices_full = [i for i in range(n_trials) if i != test_idx]\n",
    "                \n",
    "                X_train_full = X_subj[train_indices_full]\n",
    "                y_train_full = y_subj[train_indices_full]\n",
    "\n",
    "                # VALIDATION SPLIT in the  trials\n",
    "                \n",
    "                try:\n",
    "                    X_tr_np, X_val_np, y_tr_np, y_val_np = train_test_split(\n",
    "                        X_train_full, y_train_full, \n",
    "                        test_size=val_split, \n",
    "                        random_state=42,\n",
    "                        stratify=y_train_full \n",
    "                    )\n",
    "                except ValueError:\n",
    "                    \n",
    "                    X_tr_np, X_val_np, y_tr_np, y_val_np = train_test_split(\n",
    "                        X_train_full, y_train_full, \n",
    "                        test_size=val_split, \n",
    "                        random_state=42\n",
    "                    )\n",
    "                \n",
    "                \n",
    "                X_tr = torch.FloatTensor(X_tr_np).to(device)\n",
    "                y_tr = torch.FloatTensor(y_tr_np).view(-1, 1).to(device)\n",
    "                X_val = torch.FloatTensor(X_val_np).to(device)\n",
    "                y_val = torch.FloatTensor(y_val_np).view(-1, 1).to(device)\n",
    "                \n",
    "                \n",
    "                X_test = torch.FloatTensor(X_subj[test_idx:test_idx+1]).to(device)\n",
    "                y_test = torch.FloatTensor([y_subj[test_idx]]).view(-1, 1).to(device)\n",
    "\n",
    "                # Loaders\n",
    "                train_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=16, shuffle=True)\n",
    "                val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=16, shuffle=False)\n",
    "                test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=1, shuffle=False)\n",
    "\n",
    "                # Model\n",
    "                model_args[\"n_channels\"] = len(combo)\n",
    "                model = EEGLieFeatureExtractor(**model_args).to(device)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=model_args.get('lr', 1e-3))\n",
    "                criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "                best_val_loss = float(\"inf\")\n",
    "                best_state = None\n",
    "\n",
    "                \n",
    "                for epoch in range(epochs):\n",
    "                    model.train()\n",
    "                    for xb, yb in train_loader:\n",
    "                        optimizer.zero_grad()\n",
    "                        logits = model(xb)\n",
    "                        loss = criterion(logits, yb)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    \n",
    "                    val_loss, _ = eval_on_loader_bce(model, val_loader, device)\n",
    "                    \n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "                \n",
    "                if best_state:\n",
    "                    model.load_state_dict(best_state)\n",
    "                _, acc = eval_on_loader_bce(model, test_loader, device)\n",
    "                fold_accuracies.append(acc)\n",
    "\n",
    "            mean_acc = np.mean(fold_accuracies)\n",
    "            \n",
    "            \n",
    "            entry = {\n",
    "                \"subject\": f\"S{subj+1:02d}\",\n",
    "                \"combo\": combo_key,\n",
    "                \"acc\": mean_acc\n",
    "            }\n",
    "            results.append(entry)\n",
    "            print(f\"  Subj {subj+1} -> {mean_acc:.4f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:26.230585Z",
     "iopub.status.busy": "2026-02-02T11:01:26.230306Z",
     "iopub.status.idle": "2026-02-02T11:01:26.250371Z",
     "shell.execute_reply": "2026-02-02T11:01:26.249691Z",
     "shell.execute_reply.started": "2026-02-02T11:01:26.230565Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_args = {\\n    \"seq_len\": 384,\\n    \"tcn_channels\": 64,\\n    \"kernel_size\": 5,\\n    \"lstm_hidden\": 128,\\n    \"lstm_layers\": 2,\\n    \"dropout\": 0.3\\n}\\n\\n# X shape: (n_subjects, n_trials, n_channels, seq_len)\\n# y shape: (n_subjects, n_trials)\\n\\n# Within-subject LOOCV\\nwithin_results = within_subject_loocv(X, y, CHANNELS, model_args, epochs=20)\\n\\n# Cross-subject LOSO\\ncross_results = cross_subject_loso(X, y, CHANNELS, model_args, epochs=20)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model_args = {\n",
    "    \"seq_len\": 384,\n",
    "    \"tcn_channels\": 64,\n",
    "    \"kernel_size\": 5,\n",
    "    \"lstm_hidden\": 128,\n",
    "    \"lstm_layers\": 2,\n",
    "    \"dropout\": 0.3\n",
    "}\n",
    "\n",
    "# X shape: (n_subjects, n_trials, n_channels, seq_len)\n",
    "# y shape: (n_subjects, n_trials)\n",
    "\n",
    "# Within-subject LOOCV\n",
    "within_results = within_subject_loocv(X, y, CHANNELS, model_args, epochs=20)\n",
    "\n",
    "# Cross-subject LOSO\n",
    "cross_results = cross_subject_loso(X, y, CHANNELS, model_args, epochs=20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:26.251476Z",
     "iopub.status.busy": "2026-02-02T11:01:26.251209Z",
     "iopub.status.idle": "2026-02-02T11:01:26.265719Z",
     "shell.execute_reply": "2026-02-02T11:01:26.265161Z",
     "shell.execute_reply.started": "2026-02-02T11:01:26.251454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base_model_args = {\n",
    "    \n",
    "    \"seq_len\": 384,          \n",
    "    \"tcn_channels\": 64,      \n",
    "    \"kernel_size\": 5,        \n",
    "\n",
    "    \n",
    "    \"lstm_hidden\": None,     \n",
    "    \"lstm_layers\": None,     \n",
    "    \"dropout\": None , \n",
    "    \n",
    "}\n",
    "\n",
    "param_grid = [\n",
    "    #{\"lstm_hidden\": 64,  \"lstm_layers\": 1, \"dropout\": 0.2, \"lr\": 1e-3},\n",
    "    #{\"lstm_hidden\": 128, \"lstm_layers\": 1, \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"lstm_hidden\": 128, \"lstm_layers\": 2, \"dropout\": 0.3, \"lr\": 5e-4},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for cfg in param_grid:\n",
    "    print(\"\\n########################################\")\n",
    "    print(f\"### RUNNING CONFIG: {cfg}\")\n",
    "    print(\"########################################\")\n",
    "    \n",
    "    model_args = base_model_args.copy()\n",
    "    model_args.update({\n",
    "        \"lstm_hidden\": cfg[\"lstm_hidden\"],\n",
    "        \"lstm_layers\": cfg[\"lstm_layers\"],\n",
    "        \"dropout\": cfg[\"dropout\"],\n",
    "        \n",
    "    })\n",
    "\n",
    "    lr = cfg[\"lr\"]\n",
    "\n",
    "    \n",
    "    print(f\"FINAL MODEL ARGS: {model_args}\")\n",
    "\n",
    "    \n",
    "    print(\"\\n>>> STARTING CROSS-SUBJECT LOSO ...\")\n",
    "    loso_results = cross_subject_loso(X, y, CHANNELS, model_args, epochs=epochs)\n",
    "    \n",
    "    \n",
    "    save_results_json(loso_results, CROSS_DIR, \"cross\", model_args)\n",
    "    \n",
    "    \n",
    "    print(\"\\n>>> STARTING WITHIN-SUBJECT LOOCV ...\")\n",
    "    within_results = within_subject_loocv(X, y, CHANNELS, model_args, epochs=epochs)\n",
    "    \n",
    "    \n",
    "    save_results_json(within_results, WITHIN_DIR, \"within\", model_args)\n",
    "\n",
    "print(\"\\nALL DONE! Results saved in JSON format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T11:01:26.266879Z",
     "iopub.status.busy": "2026-02-02T11:01:26.266597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################\n",
      "### RUNNING CONFIG: {'lstm_hidden': 64, 'lstm_layers': 1, 'dropout': 0.2, 'lr': 0.001}\n",
      "########################################\n",
      "FINAL MODEL ARGS: {'seq_len': 384, 'tcn_channels': 64, 'kernel_size': 5, 'lstm_hidden': 64, 'lstm_layers': 1, 'dropout': 0.2}\n",
      "Learning rate: 0.001\n",
      "\n",
      "########################################\n",
      "### RUNNING CONFIG: {'lstm_hidden': 128, 'lstm_layers': 1, 'dropout': 0.3, 'lr': 0.001}\n",
      "########################################\n",
      "FINAL MODEL ARGS: {'seq_len': 384, 'tcn_channels': 64, 'kernel_size': 5, 'lstm_hidden': 128, 'lstm_layers': 1, 'dropout': 0.3}\n",
      "Learning rate: 0.001\n",
      "\n",
      "########################################\n",
      "### RUNNING CONFIG: {'lstm_hidden': 128, 'lstm_layers': 2, 'dropout': 0.3, 'lr': 0.0005}\n",
      "########################################\n",
      "FINAL MODEL ARGS: {'seq_len': 384, 'tcn_channels': 64, 'kernel_size': 5, 'lstm_hidden': 128, 'lstm_layers': 2, 'dropout': 0.3}\n",
      "Learning rate: 0.0005\n",
      "\n",
      "### RUNNING WITHIN-SUBJECT LOOCV ###\n",
      "\n",
      "===== Within-Subject | Combo: EEG.AF3 =====\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# FINAL EXPERIMENTS + SAVE\n",
    "# ==============================\n",
    "'''\n",
    "epochs = 10   \n",
    "for cfg in param_grid:\n",
    "\n",
    "    print(\"\\n########################################\")\n",
    "    print(f\"### RUNNING CONFIG: {cfg}\")\n",
    "    print(\"########################################\")\n",
    "\n",
    "    # ---- costruisci i veri model_args ----\n",
    "    model_args = base_model_args.copy()\n",
    "    model_args.update({\n",
    "        \"lstm_hidden\": cfg[\"lstm_hidden\"],\n",
    "        \"lstm_layers\": cfg[\"lstm_layers\"],\n",
    "        \"dropout\": cfg[\"dropout\"],\n",
    "    })\n",
    "\n",
    "    lr = cfg[\"lr\"]\n",
    "\n",
    "    print(\"FINAL MODEL ARGS:\", model_args)\n",
    "    print(\"Learning rate:\", lr)\n",
    "print(\"\\n### RUNNING WITHIN-SUBJECT LOOCV ###\")\n",
    "\n",
    "\n",
    "within_results = within_subject_loocv(\n",
    "    X,\n",
    "    y,\n",
    "    CHANNELS,\n",
    "    model_args,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "within_df = save_results_csv(\n",
    "    within_results,\n",
    "    save_dir=WITHIN_DIR,\n",
    "    prefix=\"within\",\n",
    "    model_args=model_args,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n### RUNNING CROSS-SUBJECT LOSO ###\")\n",
    "cross_results = cross_subject_loso(\n",
    "    X,\n",
    "    y,\n",
    "    CHANNELS,\n",
    "    model_args,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "cross_df = save_results_csv(\n",
    "    cross_results,\n",
    "    save_dir=CROSS_DIR,\n",
    "    prefix=\"cross\",\n",
    "    model_args=model_args,\n",
    "    epochs=epochs\n",
    ")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9396267,
     "sourceId": 14707303,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
