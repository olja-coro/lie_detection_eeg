{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14650418,"sourceType":"datasetVersion","datasetId":9358941}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport itertools\nimport torch.optim as optim\n\nfrom typing import Literal\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nDATA_PATH = '/kaggle/input/bio-project-data/data.npz'\nCHANNELS = [\"EEG.AF3\", \"EEG.T7\", \"EEG.Pz\", \"EEG.T8\", \"EEG.AF4\"]\nCHANNEL_TO_IDX = { c: idx for idx, c in enumerate(CHANNELS) }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:02:53.059505Z","iopub.execute_input":"2026-01-30T17:02:53.060424Z","iopub.status.idle":"2026-01-30T17:02:53.065803Z","shell.execute_reply.started":"2026-01-30T17:02:53.060394Z","shell.execute_reply":"2026-01-30T17:02:53.065034Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"def load_data(data_path, normalize: bool = True):\n    data = np.load(data_path)\n    X, y = data[\"X_raw\"], data[\"y\"]\n\n    if X.ndim != 5 or y.ndim != 3:\n        raise ValueError(\"X must be 5D and y 3D\")\n\n    n_sub, n_sess, n_chan, n_trials, n_samples = X.shape\n\n    print(f\"X original: {X.shape}\")\n    print(f\"y original: {y.shape}\")\n\n    if normalize:\n        X_mean = X.mean(axis=-1, keepdims=True)\n        X_std = X.std(axis=-1, keepdims=True) + 1e-6\n        X = (X - X_mean) / X_std\n        \n    X_transposed = X.transpose(0, 1, 3, 2, 4)  # (sub, sess, trial, chan, time)\n    X_new = X_transposed.reshape(n_sub, n_sess * n_trials, n_chan, n_samples)\n    y_new = y.reshape(n_sub, n_sess * n_trials)\n\n    if X_new.shape[1] != y_new.shape[1]:\n        raise RuntimeError(f\"Mismatch: X_new {X_new.shape}, y_new {y_new.shape}\")\n\n    unique_labels = np.unique(y_new)\n    if not set(unique_labels).issubset({0, 1}):\n        raise RuntimeError(f\"Non binary labels found: {unique_labels}\")\n\n    print(f\"X final: {X_new.shape}\")\n    print(f\"y final: {y_new.shape}\")\n\n    return X_new, y_new","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:02:56.023147Z","iopub.execute_input":"2026-01-30T17:02:56.023711Z","iopub.status.idle":"2026-01-30T17:02:56.029945Z","shell.execute_reply.started":"2026-01-30T17:02:56.023684Z","shell.execute_reply":"2026-01-30T17:02:56.029231Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"X, y = load_data(DATA_PATH, True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:02:57.966889Z","iopub.execute_input":"2026-01-30T17:02:57.967667Z","iopub.status.idle":"2026-01-30T17:02:58.126213Z","shell.execute_reply.started":"2026-01-30T17:02:57.967636Z","shell.execute_reply":"2026-01-30T17:02:58.125543Z"}},"outputs":[{"name":"stdout","text":"X original: (27, 2, 5, 25, 384)\ny original: (27, 2, 25)\nX final: (27, 50, 5, 384)\ny final: (27, 50)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class EEGLieFeatureExtractor(nn.Module):\n    def __init__(self, n_channels=5, seq_len=384, tcn_channels=64, kernel_size=5,\n                 lstm_hidden=128, lstm_layers=2, dropout=0.3):\n        super().__init__()\n        \n        # TCN: stack of 1D convs\n        self.tcn = nn.Sequential(\n            nn.Conv1d(n_channels, tcn_channels, kernel_size=kernel_size, padding=kernel_size//2),\n            nn.ReLU(),\n            nn.LayerNorm([tcn_channels, seq_len]),\n            nn.Conv1d(tcn_channels, tcn_channels, kernel_size=kernel_size, padding=kernel_size//2),\n            nn.ReLU(),\n            nn.LayerNorm([tcn_channels, seq_len]),\n            nn.MaxPool1d(2)  # Reduce sequence length\n        )\n        \n        # BiLSTM for long-term temporal dynamics\n        self.lstm = nn.LSTM(\n            input_size=tcn_channels,\n            hidden_size=lstm_hidden,\n            num_layers=lstm_layers,\n            batch_first=True,\n            bidirectional=True\n        )\n        \n        # Head (feature vector output)\n        self.classifier = nn.Linear(2 * lstm_hidden, 1)\n    \n    def forward(self, x):\n        # TCN\n        x = self.tcn(x)                     # (batch, tcn_channels, seq_len//2)\n        x = x.transpose(1, 2)               # (batch, seq_len//2, tcn_channels) for LSTM\n        \n        # LSTM\n        lstm_out, _ = self.lstm(x)          # (batch, seq_len//2, 2*lstm_hidden)\n        \n        return self.classifier(lstm_out[:, -1, :])  # (batch, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:08:06.774270Z","iopub.execute_input":"2026-01-30T17:08:06.774698Z","iopub.status.idle":"2026-01-30T17:08:06.780750Z","shell.execute_reply.started":"2026-01-30T17:08:06.774674Z","shell.execute_reply":"2026-01-30T17:08:06.780050Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"# Cross subject LOSO","metadata":{}},{"cell_type":"code","source":"def cross_subject_loso(X, y, channels, model_args, epochs=30):\n    n_subjects = X.shape[0]\n    channel_indices = list(range(len(channels)))\n    results = {}\n    \n    # Generate all non-empty combinations of channels\n    all_combos = []\n    for r in range(1, len(channels) + 1):\n        all_combos.extend(list(itertools.combinations(channel_indices, r)))\n    \n    for combo in all_combos:\n        combo_names = [channels[i] for i in combo]\n        combo_key = \", \".join(combo_names)\n        print(f\"\\n===== Analyzing Combo: {combo_key} =====\")\n        subject_accuracies = []\n        \n        for test_sub in range(n_subjects):\n            train_subs = [i for i in range(n_subjects) if i != test_sub]\n            \n            # Prepare train and test tensors\n            X_train = torch.FloatTensor(X[train_subs][:, :, combo, :]).reshape(-1, len(combo), 384).to(device)\n            y_train = torch.FloatTensor(y[train_subs]).reshape(-1, 1).to(device)\n            \n            X_test = torch.FloatTensor(X[test_sub:test_sub+1][:, :, combo, :]).reshape(-1, len(combo), 384).to(device)\n            y_test = y[test_sub].flatten()\n            \n            # Instantiate model\n            model_args['n_channels'] = len(combo)\n            model = EEGLieFeatureExtractor(**model_args).to(device)\n            optimizer = optim.Adam(model.parameters(), lr=1e-3)\n            criterion = nn.BCEWithLogitsLoss()  # use logits later if needed\n            \n            # Training loop\n            model.train()\n            for epoch in range(epochs):\n                optimizer.zero_grad()\n                outputs = model(X_train)\n                loss = criterion(outputs, y_train)\n                loss.backward()\n                optimizer.step()\n            \n            # Evaluation\n            model.eval()\n            with torch.inference_mode():\n                logits = model(X_test)\n                preds = (logits > 0).float().cpu().numpy()\n                acc = accuracy_score(y_test, preds)\n                subject_accuracies.append(acc)\n        \n        # Compute mean and std accuracy\n        mean_acc = np.mean(subject_accuracies)\n        std_acc = np.std(subject_accuracies)\n        results[combo_key] = {'mean': mean_acc, 'std': std_acc}\n        print(f\"Combo Result -> Mean: {mean_acc:.4f} | STD: {std_acc:.4f}\")\n    \n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:04:41.815220Z","iopub.execute_input":"2026-01-30T17:04:41.815768Z","iopub.status.idle":"2026-01-30T17:04:41.825208Z","shell.execute_reply.started":"2026-01-30T17:04:41.815738Z","shell.execute_reply":"2026-01-30T17:04:41.824386Z"}},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":"# Within subjects LOOCV","metadata":{}},{"cell_type":"code","source":"\ndef within_subject_loocv(X, y, channels, model_args, epochs=30):\n    n_subjects = X.shape[0]\n    channel_indices = list(range(len(channels)))\n    results = {}\n    \n    # Generate all non-empty channel combinations\n    all_combos = []\n    for r in range(1, len(channels)+1):\n        all_combos.extend(list(itertools.combinations(channel_indices, r)))\n    \n    for combo in all_combos:\n        combo_names = [channels[i] for i in combo]\n        combo_key = \", \".join(combo_names)\n        print(f\"\\n===== Analyzing Combo: {combo_key} =====\")\n        subject_accuracies = []\n        \n        # Loop over subjects\n        for sub in range(n_subjects):\n            n_trials = X.shape[1]\n            X_trials = torch.FloatTensor(X[sub][:, combo, :]).to(device)  # (n_trials, n_channels, seq_len)\n            y_trials = torch.FloatTensor(y[sub].reshape(-1,1)).to(device)\n            \n            loocv_accs = []\n            \n            # LOOCV: leave one trial out\n            for test_idx in range(n_trials):\n                train_idx = [i for i in range(n_trials) if i != test_idx]\n                \n                X_train, X_test = X_trials[train_idx], X_trials[test_idx:test_idx+1]\n                y_train, y_test = y_trials[train_idx], y_trials[test_idx:test_idx+1]\n                \n                # Instantiate model\n                model_args['n_channels'] = len(combo)\n                model = EEGLieFeatureExtractor(**model_args).to(device)\n                optimizer = optim.Adam(model.parameters(), lr=1e-3)\n                criterion = nn.BCEWithLogitsLoss()\n                \n                # Training\n                model.train()\n                for epoch in range(epochs):\n                    optimizer.zero_grad()\n                    outputs = model(X_train)\n                    loss = criterion(outputs, y_train)\n                    loss.backward()\n                    optimizer.step()\n                \n                # Evaluation\n                model.eval()\n                with torch.inference_mode():\n                    logits = model(X_test)\n                    pred = (logits > 0).float().cpu().numpy()\n                    acc = accuracy_score(y_test.cpu().numpy(), pred)\n                    loocv_accs.append(acc)\n            \n            # Average LOOCV accuracy for the subject\n            mean_sub_acc = np.mean(loocv_accs)\n            subject_accuracies.append(mean_sub_acc)\n        \n        # Average across subjects\n        mean_acc = np.mean(subject_accuracies)\n        std_acc = np.std(subject_accuracies)\n        results[combo_key] = {'mean': mean_acc, 'std': std_acc}\n        print(f\"Combo Result -> Mean: {mean_acc:.4f} | STD: {std_acc:.4f}\")\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:04:34.137280Z","iopub.execute_input":"2026-01-30T17:04:34.137982Z","iopub.status.idle":"2026-01-30T17:04:34.147903Z","shell.execute_reply.started":"2026-01-30T17:04:34.137933Z","shell.execute_reply":"2026-01-30T17:04:34.147178Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"model_args = {\n    \"seq_len\": 384,\n    \"tcn_channels\": 64,\n    \"kernel_size\": 5,\n    \"lstm_hidden\": 128,\n    \"lstm_layers\": 2,\n    \"dropout\": 0.3\n}\n\n# X shape: (n_subjects, n_trials, n_channels, seq_len)\n# y shape: (n_subjects, n_trials)\n\n# Within-subject LOOCV\nwithin_results = within_subject_loocv(X, y, CHANNELS, model_args, epochs=20)\n\n# Cross-subject LOSO\ncross_results = cross_subject_loso(X, y, CHANNELS, model_args, epochs=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T17:08:40.441764Z","iopub.execute_input":"2026-01-30T17:08:40.442332Z","iopub.status.idle":"2026-01-30T17:09:30.473924Z","shell.execute_reply.started":"2026-01-30T17:08:40.442304Z","shell.execute_reply":"2026-01-30T17:09:30.473081Z"}},"outputs":[{"name":"stdout","text":"\n===== Analyzing Combo: EEG.AF3 =====\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2273878279.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Within-subject LOOCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mwithin_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwithin_subject_loocv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHANNELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Cross-subject LOSO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/1664948888.py\u001b[0m in \u001b[0;36mwithin_subject_loocv\u001b[0;34m(X, y, channels, model_args, epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mloocv_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":63}]}