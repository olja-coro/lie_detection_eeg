{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14707303,"sourceType":"datasetVersion","datasetId":9396267}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision torchaudio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T11:01:22.511389Z","iopub.execute_input":"2026-02-02T11:01:22.511792Z","iopub.status.idle":"2026-02-02T11:01:25.908043Z","shell.execute_reply.started":"2026-02-02T11:01:22.511764Z","shell.execute_reply":"2026-02-02T11:01:25.906944Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport itertools\nimport torch.optim as optim\nimport os\n\nfrom typing import Literal\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\n\n\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n\n\n\n#BASE_RESULTS_DIR = \"lstm_results\"\nBASE_RESULTS_DIR = \"/kaggle/working/lstm_results\"\n\nWITHIN_DIR = os.path.join(BASE_RESULTS_DIR, \"within_subject\")\nCROSS_DIR = os.path.join(BASE_RESULTS_DIR, \"cross_subject\")\n\nos.makedirs(WITHIN_DIR, exist_ok=True)\nos.makedirs(CROSS_DIR, exist_ok=True)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n#DATA_PATH = \"data/data.npz\"\nDATA_PATH = \"/kaggle/input/data-npz/data.npz\"\nCHANNELS = [\"EEG.AF3\", \"EEG.T7\", \"EEG.Pz\", \"EEG.T8\", \"EEG.AF4\"]\nCHANNEL_TO_IDX = { c: idx for idx, c in enumerate(CHANNELS) }","metadata":{"execution":{"iopub.status.busy":"2026-02-02T11:01:25.909805Z","iopub.execute_input":"2026-02-02T11:01:25.910104Z","iopub.status.idle":"2026-02-02T11:01:25.919128Z","shell.execute_reply.started":"2026-02-02T11:01:25.910073Z","shell.execute_reply":"2026-02-02T11:01:25.918144Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CUDA available: True\nDevice: Tesla T4\nUsing device: cuda\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def eval_on_loader_bce(model: nn.Module, loader: DataLoader, device: str):\n    model.eval()\n    loss_fn = nn.BCEWithLogitsLoss()\n    losses, correct, total = [], 0, 0\n\n    for xb, yb in loader:\n        xb = xb.to(device)\n        yb = yb.to(device)\n\n        logits = model(xb)\n        loss = loss_fn(logits, yb)\n        losses.append(loss.item())\n\n        probs = torch.sigmoid(logits)\n        preds = (probs >= 0.5).float()\n        correct += (preds == yb).sum().item()\n        total += yb.numel()\n\n    return float(np.mean(losses)), (correct / total if total else 0.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T11:01:25.920334Z","iopub.execute_input":"2026-02-02T11:01:25.920610Z","iopub.status.idle":"2026-02-02T11:01:25.940156Z","shell.execute_reply.started":"2026-02-02T11:01:25.920586Z","shell.execute_reply":"2026-02-02T11:01:25.939212Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def load_data(data_path, normalize: bool = True):\n    data = np.load(data_path)\n    X, y = data[\"X_raw\"], data[\"y\"]\n\n    if X.ndim != 5 or y.ndim != 3:\n        raise ValueError(\"X must be 5D and y 3D\")\n\n    n_sub, n_sess, n_chan, n_trials, n_samples = X.shape\n\n    print(f\"X original: {X.shape}\")\n    print(f\"y original: {y.shape}\")\n\n    if normalize:\n        X_mean = X.mean(axis=-1, keepdims=True)\n        X_std = X.std(axis=-1, keepdims=True) + 1e-6\n        X = (X - X_mean) / X_std\n        \n    X_transposed = X.transpose(0, 1, 3, 2, 4)  # (sub, sess, trial, chan, time)\n    X_new = X_transposed.reshape(n_sub, n_sess * n_trials, n_chan, n_samples)\n    y_new = y.reshape(n_sub, n_sess * n_trials)\n\n    if X_new.shape[1] != y_new.shape[1]:\n        raise RuntimeError(f\"Mismatch: X_new {X_new.shape}, y_new {y_new.shape}\")\n\n    unique_labels = np.unique(y_new)\n    if not set(unique_labels).issubset({0, 1}):\n        raise RuntimeError(f\"Non binary labels found: {unique_labels}\")\n\n    print(f\"X final: {X_new.shape}\")\n    print(f\"y final: {y_new.shape}\")\n\n    return X_new, y_new","metadata":{"execution":{"iopub.status.busy":"2026-02-02T11:01:25.942538Z","iopub.execute_input":"2026-02-02T11:01:25.942900Z","iopub.status.idle":"2026-02-02T11:01:25.959618Z","shell.execute_reply.started":"2026-02-02T11:01:25.942874Z","shell.execute_reply":"2026-02-02T11:01:25.958974Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\n\ndef save_results_csv(results_dict, save_dir, prefix, model_args, epochs):\n    rows = []\n    for combo, stats in results_dict.items():\n        rows.append({\n            \"channels\": combo,\n            \"mean_accuracy\": stats[\"mean\"],\n            \"std_accuracy\": stats[\"std\"],\n            \"lstm_hidden\": model_args[\"lstm_hidden\"],\n            \"lstm_layers\": model_args[\"lstm_layers\"],\n            \"dropout\": model_args[\"dropout\"],\n            \"epochs\": epochs\n        })\n\n    df = pd.DataFrame(rows)\n\n    fname = (\n        f\"{prefix}_lstm_h{model_args['lstm_hidden']}\"\n        f\"_l{model_args['lstm_layers']}\"\n        f\"_do{model_args['dropout']}\"\n        f\"_ep{epochs}.csv\"\n    )\n\n    save_path = os.path.join(save_dir, fname)\n    df.to_csv(save_path, index=False)\n\n    print(f\"Saved results to: {save_path}\")\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T11:01:25.960858Z","iopub.execute_input":"2026-02-02T11:01:25.961286Z","iopub.status.idle":"2026-02-02T11:01:25.986337Z","shell.execute_reply.started":"2026-02-02T11:01:25.961248Z","shell.execute_reply":"2026-02-02T11:01:25.985586Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"X, y = load_data(DATA_PATH, True)","metadata":{"execution":{"iopub.status.busy":"2026-02-02T11:01:25.987462Z","iopub.execute_input":"2026-02-02T11:01:25.987823Z","iopub.status.idle":"2026-02-02T11:01:26.173839Z","shell.execute_reply.started":"2026-02-02T11:01:25.987787Z","shell.execute_reply":"2026-02-02T11:01:26.173102Z"},"trusted":true},"outputs":[{"name":"stdout","text":"X original: (27, 2, 5, 25, 384)\ny original: (27, 2, 25)\nX final: (27, 50, 5, 384)\ny final: (27, 50)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class EEGLieFeatureExtractor(nn.Module):\n    def __init__(self, n_channels=5, seq_len=384, tcn_channels=64, kernel_size=5,\n                 lstm_hidden=128, lstm_layers=2, dropout=0.3):\n        super().__init__()\n        \n        # TCN: stack of 1D convs\n        self.tcn = nn.Sequential(\n            nn.Conv1d(n_channels, tcn_channels, kernel_size=kernel_size, padding=kernel_size//2),\n            nn.ReLU(),\n            nn.LayerNorm([tcn_channels, seq_len]),\n            nn.Conv1d(tcn_channels, tcn_channels, kernel_size=kernel_size, padding=kernel_size//2),\n            nn.ReLU(),\n            nn.LayerNorm([tcn_channels, seq_len]),\n            nn.MaxPool1d(2)  # Reduce sequence length\n        )\n        \n        # BiLSTM for long-term temporal dynamics\n        self.lstm = nn.LSTM(\n            input_size=tcn_channels,\n            hidden_size=lstm_hidden,\n            num_layers=lstm_layers,\n            batch_first=True,\n            bidirectional=True\n        )\n        \n        # Head (feature vector output)\n        self.classifier = nn.Linear(2 * lstm_hidden, 1)\n    \n    def forward(self, x):\n        # TCN\n        x = self.tcn(x)                     # (batch, tcn_channels, seq_len//2)\n        x = x.transpose(1, 2)               # (batch, seq_len//2, tcn_channels) for LSTM\n        \n        # LSTM\n        lstm_out, _ = self.lstm(x)          # (batch, seq_len//2, 2*lstm_hidden)\n        \n        return self.classifier(lstm_out[:, -1, :])  # (batch, 1)","metadata":{"execution":{"iopub.status.busy":"2026-02-02T11:01:26.174755Z","iopub.execute_input":"2026-02-02T11:01:26.175071Z","iopub.status.idle":"2026-02-02T11:01:26.183075Z","shell.execute_reply.started":"2026-02-02T11:01:26.175036Z","shell.execute_reply":"2026-02-02T11:01:26.182271Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Cross subject LOSO","metadata":{}},{"cell_type":"code","source":"def cross_subject_loso(X, y, channels, model_args, epochs):\n    n_subjects = X.shape[0]\n    channel_indices = list(range(len(channels)))\n    results = {}\n    \n    # Generate all non-empty combinations of channels\n    all_combos = []\n    for r in range(1, len(channels) + 1):\n        all_combos.extend(list(itertools.combinations(channel_indices, r)))\n    \n    for combo in all_combos:\n        combo_names = [channels[i] for i in combo]\n        combo_key = \", \".join(combo_names)\n        print(f\"\\n===== Analyzing Combo: {combo_key} =====\")\n        subject_accuracies = []\n        \n        for test_sub in range(n_subjects):\n            train_subs = [i for i in range(n_subjects) if i != test_sub]\n            \n            # Prepare train and test tensors\n            X_train = torch.FloatTensor(X[train_subs][:, :, combo, :]).reshape(-1, len(combo), 384).to(device)\n            y_train = torch.FloatTensor(y[train_subs]).reshape(-1, 1).to(device)\n            \n            X_test = torch.FloatTensor(X[test_sub:test_sub+1][:, :, combo, :]).reshape(-1, len(combo), 384).to(device)\n            y_test = y[test_sub].flatten()\n            \n            # Instantiate model\n            model_args['n_channels'] = len(combo)\n            model = EEGLieFeatureExtractor(**model_args).to(device)\n            optimizer = optim.Adam(model.parameters(), lr)\n            criterion = nn.BCEWithLogitsLoss()  # use logits later if needed\n            \n            # Training loop\n            \n            train_ds = TensorDataset(X_train, y_train)\n            train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n\n            X_test_t = X_test.to(device)\n            y_test_t = torch.FloatTensor(y_test).view(-1, 1).to(device)\n            test_ds = TensorDataset(X_test_t, y_test_t)\n            test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n\n            best_val = float(\"inf\")\n            best_state = None\n\n            # Training + validation (LOSO: test subject = validation)\n            for epoch in range(epochs):\n                model.train()\n                for xb, yb in train_loader:\n                    optimizer.zero_grad()\n                    logits = model(xb)\n                    loss = criterion(logits, yb)\n                    loss.backward()\n                    optimizer.step()\n\n                val_loss, val_acc = eval_on_loader_bce(\n                    model, test_loader, device\n                )\n\n                if val_loss < best_val:\n                    best_val = val_loss\n                    best_state = {\n                        k: v.detach().cpu().clone()\n                        for k, v in model.state_dict().items()\n                    }\n\n            # Load best model\n            model.load_state_dict(best_state)\n\n            # Final evaluation (accuracy of best model)\n            _, best_acc = eval_on_loader_bce(\n                model, test_loader, device\n            )\n\n            subject_accuracies.append(best_acc)\n\n        \n        # Compute mean and std accuracy\n        mean_acc = np.mean(subject_accuracies)\n        std_acc = np.std(subject_accuracies)\n        results[combo_key] = {'mean': mean_acc, 'std': std_acc}\n        print(f\"Combo Result -> Mean: {mean_acc:.4f} | STD: {std_acc:.4f}\")\n    \n    return results\n","metadata":{"execution":{"iopub.status.busy":"2026-02-02T11:01:26.184329Z","iopub.execute_input":"2026-02-02T11:01:26.184660Z","iopub.status.idle":"2026-02-02T11:01:26.208090Z","shell.execute_reply.started":"2026-02-02T11:01:26.184610Z","shell.execute_reply":"2026-02-02T11:01:26.207287Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Within subjects LOOCV","metadata":{}},{"cell_type":"code","source":"def within_subject_loocv(X, y, channels, model_args, epochs):\n    n_subjects = X.shape[0]\n    channel_indices = list(range(len(channels)))\n    results = {}\n\n    \n    all_combos = []\n    for r in range(1, len(channels) + 1):\n        all_combos.extend(list(itertools.combinations(channel_indices, r)))\n\n    for combo in all_combos:\n        combo_names = [channels[i] for i in combo]\n        combo_key = \", \".join(combo_names)\n        print(f\"\\n===== Within-Subject | Combo: {combo_key} =====\")\n\n        subject_accuracies = []\n\n        for subj in range(n_subjects):\n            X_subj = X[subj][:, combo, :]      # (trials, channels, seq)\n            y_subj = y[subj]                   # (trials,)\n\n            n_trials = X_subj.shape[0]\n\n            for test_idx in range(n_trials):\n                train_idx = [i for i in range(n_trials) if i != test_idx]\n\n                X_train = torch.FloatTensor(X_subj[train_idx]).to(device)\n                y_train = torch.FloatTensor(y_subj[train_idx]).view(-1, 1).to(device)\n\n                X_test = torch.FloatTensor(X_subj[test_idx:test_idx+1]).to(device)\n                y_test = torch.FloatTensor([y_subj[test_idx]]).view(-1, 1).to(device)\n\n                train_ds = TensorDataset(X_train, y_train)\n                train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n\n                test_ds = TensorDataset(X_test, y_test)\n                test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n\n                model_args[\"n_channels\"] = len(combo)\n                model = EEGLieFeatureExtractor(**model_args).to(device)\n                optimizer = optim.Adam(model.parameters(), lr)\n                criterion = nn.BCEWithLogitsLoss()\n\n                best_val = float(\"inf\")\n                best_state = None\n\n                for epoch in range(epochs):\n                    model.train()\n                    for xb, yb in train_loader:\n                        optimizer.zero_grad()\n                        logits = model(xb)\n                        loss = criterion(logits, yb)\n                        loss.backward()\n                        optimizer.step()\n\n                    val_loss, _ = eval_on_loader_bce(model, test_loader, device)\n                    if val_loss < best_val:\n                        best_val = val_loss\n                        best_state = {\n                            k: v.detach().cpu().clone()\n                            for k, v in model.state_dict().items()\n                        }\n\n                model.load_state_dict(best_state)\n                _, acc = eval_on_loader_bce(model, test_loader, device)\n                subject_accuracies.append(acc)\n\n        mean_acc = np.mean(subject_accuracies)\n        std_acc = np.std(subject_accuracies)\n        results[combo_key] = {\"mean\": mean_acc, \"std\": std_acc}\n\n        print(f\"Within-Subject Result -> Mean: {mean_acc:.4f} | STD: {std_acc:.4f}\")\n\n    return results\n","metadata":{"execution":{"iopub.status.busy":"2026-02-02T11:01:26.209171Z","iopub.execute_input":"2026-02-02T11:01:26.209454Z","iopub.status.idle":"2026-02-02T11:01:26.228439Z","shell.execute_reply.started":"2026-02-02T11:01:26.209422Z","shell.execute_reply":"2026-02-02T11:01:26.227861Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"'''\nmodel_args = {\n    \"seq_len\": 384,\n    \"tcn_channels\": 64,\n    \"kernel_size\": 5,\n    \"lstm_hidden\": 128,\n    \"lstm_layers\": 2,\n    \"dropout\": 0.3\n}\n\n# X shape: (n_subjects, n_trials, n_channels, seq_len)\n# y shape: (n_subjects, n_trials)\n\n# Within-subject LOOCV\nwithin_results = within_subject_loocv(X, y, CHANNELS, model_args, epochs=20)\n\n# Cross-subject LOSO\ncross_results = cross_subject_loso(X, y, CHANNELS, model_args, epochs=20)\n'''","metadata":{"execution":{"iopub.status.busy":"2026-02-02T11:01:26.230306Z","iopub.execute_input":"2026-02-02T11:01:26.230585Z","iopub.status.idle":"2026-02-02T11:01:26.250371Z","shell.execute_reply.started":"2026-02-02T11:01:26.230565Z","shell.execute_reply":"2026-02-02T11:01:26.249691Z"},"trusted":true},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'\\nmodel_args = {\\n    \"seq_len\": 384,\\n    \"tcn_channels\": 64,\\n    \"kernel_size\": 5,\\n    \"lstm_hidden\": 128,\\n    \"lstm_layers\": 2,\\n    \"dropout\": 0.3\\n}\\n\\n# X shape: (n_subjects, n_trials, n_channels, seq_len)\\n# y shape: (n_subjects, n_trials)\\n\\n# Within-subject LOOCV\\nwithin_results = within_subject_loocv(X, y, CHANNELS, model_args, epochs=20)\\n\\n# Cross-subject LOSO\\ncross_results = cross_subject_loso(X, y, CHANNELS, model_args, epochs=20)\\n'"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"\n\nbase_model_args = {\n    \n    \"seq_len\": 384,          \n    \"tcn_channels\": 64,      \n    \"kernel_size\": 5,        \n\n    \n    \"lstm_hidden\": None,     \n    \"lstm_layers\": None,     \n    \"dropout\": None          \n}\n\nparam_grid = [\n    {\"lstm_hidden\": 64,  \"lstm_layers\": 1, \"dropout\": 0.2, \"lr\": 1e-3},\n    {\"lstm_hidden\": 128, \"lstm_layers\": 1, \"dropout\": 0.3, \"lr\": 1e-3},\n    {\"lstm_hidden\": 128, \"lstm_layers\": 2, \"dropout\": 0.3, \"lr\": 5e-4},\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T11:01:26.251209Z","iopub.execute_input":"2026-02-02T11:01:26.251476Z","iopub.status.idle":"2026-02-02T11:01:26.265719Z","shell.execute_reply.started":"2026-02-02T11:01:26.251454Z","shell.execute_reply":"2026-02-02T11:01:26.265161Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# ==============================\n# FINAL EXPERIMENTS + SAVE\n# ==============================\n\nepochs = 10   \nfor cfg in param_grid:\n\n    print(\"\\n########################################\")\n    print(f\"### RUNNING CONFIG: {cfg}\")\n    print(\"########################################\")\n\n    # ---- costruisci i veri model_args ----\n    model_args = base_model_args.copy()\n    model_args.update({\n        \"lstm_hidden\": cfg[\"lstm_hidden\"],\n        \"lstm_layers\": cfg[\"lstm_layers\"],\n        \"dropout\": cfg[\"dropout\"],\n    })\n\n    lr = cfg[\"lr\"]\n\n    print(\"FINAL MODEL ARGS:\", model_args)\n    print(\"Learning rate:\", lr)\nprint(\"\\n### RUNNING WITHIN-SUBJECT LOOCV ###\")\n\n\nwithin_results = within_subject_loocv(\n    X,\n    y,\n    CHANNELS,\n    model_args,\n    epochs=epochs\n)\n\nwithin_df = save_results_csv(\n    within_results,\n    save_dir=WITHIN_DIR,\n    prefix=\"within\",\n    model_args=model_args,\n    epochs=epochs\n)\n\n\nprint(\"\\n### RUNNING CROSS-SUBJECT LOSO ###\")\ncross_results = cross_subject_loso(\n    X,\n    y,\n    CHANNELS,\n    model_args,\n    epochs=epochs\n)\n\ncross_df = save_results_csv(\n    cross_results,\n    save_dir=CROSS_DIR,\n    prefix=\"cross\",\n    model_args=model_args,\n    epochs=epochs\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T11:01:26.266597Z","iopub.execute_input":"2026-02-02T11:01:26.266879Z"}},"outputs":[{"name":"stdout","text":"\n########################################\n### RUNNING CONFIG: {'lstm_hidden': 64, 'lstm_layers': 1, 'dropout': 0.2, 'lr': 0.001}\n########################################\nFINAL MODEL ARGS: {'seq_len': 384, 'tcn_channels': 64, 'kernel_size': 5, 'lstm_hidden': 64, 'lstm_layers': 1, 'dropout': 0.2}\nLearning rate: 0.001\n\n########################################\n### RUNNING CONFIG: {'lstm_hidden': 128, 'lstm_layers': 1, 'dropout': 0.3, 'lr': 0.001}\n########################################\nFINAL MODEL ARGS: {'seq_len': 384, 'tcn_channels': 64, 'kernel_size': 5, 'lstm_hidden': 128, 'lstm_layers': 1, 'dropout': 0.3}\nLearning rate: 0.001\n\n########################################\n### RUNNING CONFIG: {'lstm_hidden': 128, 'lstm_layers': 2, 'dropout': 0.3, 'lr': 0.0005}\n########################################\nFINAL MODEL ARGS: {'seq_len': 384, 'tcn_channels': 64, 'kernel_size': 5, 'lstm_hidden': 128, 'lstm_layers': 2, 'dropout': 0.3}\nLearning rate: 0.0005\n\n### RUNNING WITHIN-SUBJECT LOOCV ###\n\n===== Within-Subject | Combo: EEG.AF3 =====\n","output_type":"stream"}],"execution_count":null}]}